# Model Configuration
#
# Defines available LLM models and their properties.
# Configure model-specific settings like context windows, costs, and capabilities.

models:
  # OpenAI Models
  gpt-4o:
    provider: openai
    context_window: 128000
    max_output_tokens: 4096
    cost_per_1k_input_tokens: 0.0050
    cost_per_1k_output_tokens: 0.0150
    capabilities:
      - text_generation
      - function_calling
      - json_mode
    recommended_for:
      - complex_extraction
      - structured_output
      - multi_step_reasoning

  gpt-4o-mini:
    provider: openai
    context_window: 128000
    max_output_tokens: 16384
    cost_per_1k_input_tokens: 0.00015
    cost_per_1k_output_tokens: 0.00060
    capabilities:
      - text_generation
      - function_calling
      - json_mode
    recommended_for:
      - simple_extraction
      - classification
      - batch_processing

  # Anthropic Models
  claude-3-5-sonnet-20241022:
    provider: anthropic
    context_window: 200000
    max_output_tokens: 8192
    cost_per_1k_input_tokens: 0.0030
    cost_per_1k_output_tokens: 0.0150
    capabilities:
      - text_generation
      - function_calling
      - extended_context
    recommended_for:
      - long_documents
      - detailed_analysis
      - complex_extraction

  claude-3-haiku-20240307:
    provider: anthropic
    context_window: 200000
    max_output_tokens: 4096
    cost_per_1k_input_tokens: 0.00025
    cost_per_1k_output_tokens: 0.00125
    capabilities:
      - text_generation
      - fast_processing
    recommended_for:
      - simple_extraction
      - high_volume_processing
      - classification

  # Google Models
  gemini-1.5-pro:
    provider: google
    context_window: 2000000
    max_output_tokens: 8192
    cost_per_1k_input_tokens: 0.00125
    cost_per_1k_output_tokens: 0.00500
    capabilities:
      - text_generation
      - multimodal
      - extremely_long_context
    recommended_for:
      - extremely_long_documents
      - multimodal_processing
      - batch_analysis

  gemini-1.5-flash:
    provider: google
    context_window: 1000000
    max_output_tokens: 8192
    cost_per_1k_input_tokens: 0.000075
    cost_per_1k_output_tokens: 0.0003
    capabilities:
      - text_generation
      - fast_processing
      - long_context
    recommended_for:
      - high_volume_processing
      - cost_sensitive_workloads
      - batch_operations

# Default model selections by use case
defaults:
  simple_extraction: gpt-4o-mini
  complex_extraction: gpt-4o
  long_document: claude-3-5-sonnet-20241022
  high_volume: gemini-1.5-flash
  multimodal: gemini-1.5-pro
  cost_sensitive: gemini-1.5-flash

# Budget management
budget:
  monthly_limit_usd: 300.0
  warn_at_percent: 75
  stop_at_percent: 95
  track_by_model: true

# Fallback strategy
fallback:
  enabled: true
  strategy: "cost_efficient"  # Options: cost_efficient, capability_match, fastest
  max_retries: 2
